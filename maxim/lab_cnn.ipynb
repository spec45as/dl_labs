{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 3. Обучение сверточных нейросетей в Pytorch\n",
    "\n",
    "На этом семинаре мы будем обучать LeNet-5 на данных MNIST (и не только :). Мы наконец перестанем реализовывать все самостоятельно и будем пользоваться готовым функционалом pytorch.\n",
    "\n",
    "Для начала ознакомимся с парой примеров обучения модели:\n",
    "* [Пример 1](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/convolutional_neural_network/main.py)\n",
    "* [Пример 2](https://github.com/jcjohnson/pytorch-examples/blob/master/nn/two_layer_net_nn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных в pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз мы будем работать MNIST: он отличается от digits разрещением изображений (28x28 вместо 8x8) и числом объектов (60000 в обучении вместо 1797). \n",
    "\n",
    "В pytorch есть своя обертка, позволяющая скачивать MNIST, но нам будет удобнее скачать его самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо обучающей и контрольной, нам понадобится валидационная выборка, чтобы настраивать гиперпараметры. Ее можно отделить от обучающей выборки (например, 25% = 15000 объектов). Однако модель несколько долго обучается даже на 75% обучающей выборки (несколько минут), что не очень хорошо для семинара. Поэтому для валидационных целей предлагается обучающую выборку также сжать до 15000 объектов. Финальную модель будем обучать по всей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "np.random.seed(0)\n",
    "idxs = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, y_train = X_train[idxs], y_train[idxs]\n",
    "                            \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pytorch есть удобный класс для генерации батчей - DataLoader. Ему на вход надо подать объект класса TensorDataset, слудащий оберткой над матрицами данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loader(X, y, batch_size=64):\n",
    "    train = torch.utils.data.TensorDataset(torch.from_numpy(X).float(), \n",
    "                                       torch.from_numpy(y))\n",
    "    train_loader = torch.utils.data.DataLoader(train, \n",
    "                                               batch_size=batch_size)\n",
    "    return train_loader\n",
    "\n",
    "# for final model:\n",
    "train_loader_full = get_loader(X_train, y_train) \n",
    "test_loader = get_loader(X_test, y_test)\n",
    "# for validation purposes:\n",
    "train_loader = get_loader(X_train[:15000], y_train[:15000])\n",
    "val_loader = get_loader(X_train[15000:30000], y_train[15000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check number of objects\n",
    "val_loader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание модели LeNet-5\n",
    "\n",
    "Сверточный слой (из презентации Антона Осокина):\n",
    "![Слайд про свертки из презентации Антона Осокина](https://github.com/nadiinchi/dl_labs/raw/master/convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо реализовать LeNet-5:\n",
    "\n",
    "![Архитектура LeNet-5](https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/09/lenet-5-825x285.png?x64257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберите нейросеть в соответствии с изображениями и примерами кода, которые были даны выше. В качестве нелинейности используйте ReLU (после всех сверточных и полносвязных слоев). Кроме того, нейросеть должна поддерживать увеличение числа сверток во всех сверточных слоях в k раз. \n",
    "\n",
    "Обратите внимание, что на схеме вход имеет размерность 32x32, а у нас - 28x28 (см. ячейку выше). Применять софтмакс в конце прохода вперед не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        super(CNN, self).__init__()\n",
    "        ### your code here: define layers\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        ### your code here: transform x using layers\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем параметры нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(param.data.numpy().size for param \\\n",
    "               in model.parameters() if param.requires_grad)\n",
    "\n",
    "count_parameters(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss includes softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также определим устройство, на котором будем хранить данные и модель (cpu или gpu), и перенем на него модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время обучения модели удобно контролировать качество и на обучении, и на контроле (валидации) - возникает дублирующий код. Поэтому мы вынесем в отдельную функцию оценку модели, и в отдельную функцию - эпоху обучения. Это позволит также честно оценивать значение критерия качества на всей обучающей выборке по окончании эпохи (а не усреднять значения на минибатчах).\n",
    "\n",
    "В прототипах указано про train и eval mode: в нашем случае они не нужны (были бы нужны, если бы мы использовали дропаут или батч-нормализацию, к примеру). Но чтобы вы могли использовать этот код в будущем, лучше указывать переключение режима."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    for each batch \n",
    "    performs forward and backward pass and parameters update \n",
    "    \n",
    "    Input:\n",
    "    model: instance of model (example defined above)\n",
    "    optimizer: instance of optimizer (defined above)\n",
    "    train_loader: instance of DataLoader\n",
    "    \n",
    "    Returns:\n",
    "    nothing\n",
    "    \n",
    "    Do not forget to set net to train mode!\n",
    "    \"\"\"\n",
    "    ### your code here\n",
    "    \n",
    "\n",
    "def evaluate_loss_acc(loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates loss and accuracy on the whole dataset\n",
    "    \n",
    "    Input:\n",
    "    loader:  instance of DataLoader\n",
    "    model: instance of model (examle defined above)\n",
    "    \n",
    "    Returns:\n",
    "    (loss, accuracy)\n",
    "    \n",
    "    Do not forget to set net to eval mode!\n",
    "    \"\"\"\n",
    "    ### your code here\n",
    "    \n",
    "    \n",
    "def train(model, opt, train_loader, test_loader, criterion, n_epochs, \\\n",
    "          device, verbose=True):\n",
    "    \"\"\"\n",
    "    Performs training of the model and prints progress\n",
    "    \n",
    "    Input:\n",
    "    model: instance of model (example defined above)\n",
    "    opt: instance of optimizer \n",
    "    train_loader: instance of DataLoader\n",
    "    test_loader: instance of DataLoader (for evaluation)\n",
    "    n_epochs: int\n",
    "    \n",
    "    Returns:\n",
    "    4 lists: train_log, train_acc_log, val_log, val_acc_log\n",
    "    with corresponding metrics per epoch\n",
    "    \"\"\"\n",
    "    train_log, train_acc_log = [], []\n",
    "    val_log, val_acc_log = [], []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_epoch(model, opt, train_loader, criterion, device)\n",
    "        train_loss, train_acc = evaluate_loss_acc(train_loader, \n",
    "                                                  model, device)\n",
    "        val_loss, val_acc = evaluate_loss_acc(test_loader, model, \n",
    "                                              device)\n",
    "\n",
    "        train_log.append(train_loss)\n",
    "        train_acc_log.append(train_acc)\n",
    "\n",
    "        val_log.append(val_loss)\n",
    "        val_acc_log.append(val_acc)\n",
    "        \n",
    "        if verbose:\n",
    "             print (('Epoch [%d/%d], Loss (train/test): %.4f/%.4f,'+\\\n",
    "               ' Acc (train/test): %.4f/%.4f' )\n",
    "                   %(epoch+1, n_epochs, \\\n",
    "                     train_loss, val_loss, train_acc, val_acc))\n",
    "            \n",
    "    return train_log, train_acc_log, val_log, val_acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите нейронную сеть, используя определенные функции. Установите Adam в качестве оптимизатора, learning_rate=0.001, число эпох - 20. В качестве test_loader используйте валидационную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результат прохождения изображения через слои. Код ниже отрисовывает сетку изображений: первый столбец - изображения цифр, следующие 6 столбцов - результаты применения фильтров к ним. Чтобы им воспользоваться, сохраните в x переменную, храняющую батч из 10 изображений, в y - результат применения первого слоя к x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(x, y):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for im in range(10):\n",
    "        plt.subplot(11, 7, im*7+1)\n",
    "        plt.imshow(x.data[im, 0])\n",
    "        plt.axis(\"off\")\n",
    "        for i in range(6):\n",
    "            plt.subplot(11, 7, im*7+i+2)\n",
    "            plt.imshow(y.data[im, i].numpy())\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем визуализируйте результат применения второго сверточного слоя (после всех предыдущих слоев):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Подбор длины шага и размера батча"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики точности (accuracy) на обучающей и валидационной выборке в зависимости от номера эпохи при разных параметрах обучения: learning rate$ \\in \\{0.0001, 0.001, 0.01\\}$, batch size $\\in \\{64, 256\\}$. \n",
    "\n",
    "Лучше всего отображать кривые для обучения на левом графике, кривые для валидации - на правом с общей осью y (plt.ylim).\n",
    "\n",
    "Как влияют длина шага и размер батча на итоговое качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение архитектуры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте модифицировать архитектуру нейросети: увеличить число фильтров и уменьшить число полносвязных слоев. \n",
    "\n",
    "Впишите цифры в скобки:\n",
    "* LeNet-5 классич. (6 и 16 сверток):  качество на обучении: ( )  качество на валидации: ( )\n",
    "* Увеличение в 4 раза (24 и 64 сверток):  качество на обучении: ( )  качество на валидации: ( )\n",
    "* Удаление полносвзяного слоя: предыдущая нейросеть с 1 полносвязным слоем: качество на обучении: ( )  качество на валидации: ( )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите длину шага, размер батча и архитектуру по валидационной выборке, обучите нейросеть на полной обучающей выборке и выведите качество на контрольной выборке. Хуже ли оно, чем на валидационной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
