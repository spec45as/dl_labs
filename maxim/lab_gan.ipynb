{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генеративно-состязательные сети (Generative Adversarial Networks)\n",
    "\n",
    "В задании предлагается реализовать GAN, обучить её на MNIST, оценить правдоподобие и сделать выводы.\n",
    "\n",
    "Необходимая теория приведена ниже.\n",
    "\n",
    "Актуальная версия доступна по адресу https://github.com/nadiinchi/dl_labs/blob/master/lab_gan.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Дана выборка независимых одинаково распределенных величин из истинного распределения $x_i \\sim p_d(x)$, $i = 1, \\dots, N$.\n",
    "\n",
    "Задача - построить вероятностную модель $p_\\theta(x)$ истинного распределения $p_d(x)$.\n",
    "\n",
    "Распределение $p_\\theta(x)$ должно позволять как оценить плотность вероятности для данного объекта $x$, так и сэмплировать $x \\sim p_\\theta(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вероятностная модель\n",
    "$z \\in \\mathbb{R}^d$ - локальная латентная переменная, т. е. своя для каждого объекта $x \\in \\mathbb{R}^D$.\n",
    "\n",
    "Генеративный процесс вариационного автокодировщика:\n",
    "1. Сэмплируем $z \\sim p(z)$.\n",
    "2. $x = G_\\theta(z)$.\n",
    "\n",
    "Параметры преобразования $G_\\theta(z)$ задаются нейросетью с весами $\\theta$, получающей на вход вектор $z$.\n",
    "\n",
    "Индуцированная генеративным процессом плотность вероятности объекта $x$:\n",
    "\n",
    "$$p_\\theta(x) = \\mathbb{E}_{z \\sim p(z)} \\delta(x = G(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка логарифма правдоподобия\n",
    "Для оценки логарифма правдоподобия используется метод Парзеновского окна/ядерного сглаживания (англ. Kernel Density Estimation/Parzen–Rosenblatt window method). Концептуально он заключается в том, что мы сглаживаем модельное распределение, и по этому сглаженному распределению вычисляем правдоподобие модели.\n",
    "\n",
    "$$p_\\theta(x) = \\mathbb{E}_{z \\sim p(z)} \\delta(x = G(z)) \\approx \\frac{1}{Mh^D}\\sum_{i=1}^M K\\left(\\frac{x - G_\\theta(z_i)}{h}\\right)$$\n",
    "\n",
    "Здесь $K(x)$ - любое распределение, а $h$ - ширина окна. Тогда выполняется\n",
    "\n",
    "$$\\mathbb{E}_{x \\sim p_d} \\log p_\\theta(x) \\approx  \\frac{1}{N}\\sum_{i=1}^{N} \\log \\frac{1}{Mh^D}\\sum_{j=1}^M K\\left(\\frac{x_i - G_\\theta(z_j)}{h}\\right)$$\n",
    "\n",
    "В генеративно-состязательных сетях для оценки правдоподобия используется стандартное нормальное распределение $K(x) = N(x | 0, I)$. Тогда получаем\n",
    "\n",
    "$$\\mathbb{E}_{x \\sim p_d} \\log p_\\theta(x) \\approx  \\frac{1}{N}\\sum_{i=1}^{N} \\log \\frac{1}{M}\\sum_{j=1}^M \\prod_{k=1}^D\\frac{1}{\\sqrt{2 \\pi} \\sigma}\\exp\\left(-\\frac{(x_{i,k} - G(z_j)_k)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "Коэффициент $\\sigma$ настраивается на валидационной выборке и с его помощью считается правдоподобие тестовой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка, нормировка и визуалиация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False   # если есть pytorch с cuda, этот флаг может ускорить обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = MNIST('mnist', download=True, train=True)\n",
    "train_data = TensorDataset(data.train_data.view(-1, 28 * 28).float() / 255, data.train_labels)\n",
    "data = MNIST('mnist', download=True, train=False)\n",
    "test_data = TensorDataset(data.test_data.view(-1, 28 * 28).float() / 255, data.test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.data_tensor = nn.AvgPool2d(2, 2)(Variable(train_data.data_tensor.view(-1, 28, 28))).data.view(-1, 196)\n",
    "test_data.data_tensor = nn.AvgPool2d(2, 2)(Variable(test_data.data_tensor.view(-1, 28, 28))).data.view(-1, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = TensorDataset(test_data.data_tensor[:5000], test_data.target_tensor[:5000])\n",
    "test_data = TensorDataset(test_data.data_tensor[5000:], test_data.target_tensor[5000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_images(x):\n",
    "    plt.figure(figsize=(12, 12 / 10 * (x.shape[0] // 10 + 1)))\n",
    "    x = x.view(-1, 14, 14)\n",
    "    for i in range(x.shape[0]):\n",
    "        plt.subplot(x.shape[0] // 10 + 1, 10, i + 1)\n",
    "        plt.imshow(x.data[i].numpy(), cmap='Greys_r', vmin=0, vmax=1, interpolation='lanczos')\n",
    "        plt.axis('off')\n",
    "\n",
    "show_images(Variable(train_data[:10][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 15\n",
    "digit_size = 14\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "def draw_manifold(generator):\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "\n",
    "            x_decoded = generator(z_sample)\n",
    "            digit = x_decoded\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap='Greys_r', vmin=0, vmax=1, interpolation='lanczos')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"\n",
    "        Запоминает размерности, в которые при проходе\n",
    "        вперед будут переводиться все объекты.\n",
    "        Например,\n",
    "            input = torch.zeros(100, 196)\n",
    "            reshape_layer = Reshape(1, 14, 14)\n",
    "            reshape_layer(input)\n",
    "        возвращает тензор размерности (100, 1, 14, 14).\n",
    "            input = torch.zeros(100, 1, 14, 14)\n",
    "            reshape_layer = Reshape(-1)\n",
    "            reshape_layer(input)\n",
    "        наоборот вернет тензор размерности (100, 196).\n",
    "        \"\"\"\n",
    "        super(type(self), self).__init__()\n",
    "        self.dims = args\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Возвращает тензор с измененными размерностями объектов.\n",
    "        Вход: input, FloatTensor или Variable.\n",
    "        Возвращаемое значение: FloatTensor или Variable.\n",
    "        \"\"\"\n",
    "        return input.view(input.size(0), *self.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GAN(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        \"\"\"\n",
    "        Инициализирует веса модели.\n",
    "        Вход: d, int - размерность латентного пространства.\n",
    "        Вход: D, int - размерность пространства объектов.\n",
    "        \"\"\"\n",
    "        super(type(self), self).__init__()\n",
    "        self.d = d\n",
    "        # Те, у кого достаточно вычислительных ресурсов, могут попробовать\n",
    "        # сверточные архитектуры генератора и дискриминатора.\n",
    "        # Для того, чтобы в рамках одного Sequential переключаться между\n",
    "        # сверточными и полносвязными слоями, можно использовать Reshape,\n",
    "        # например:\n",
    "        # nn.Sequential(\n",
    "        #     Reshape(1, 14, 14),\n",
    "        #     nn.Conv2d(1, 6, 5, 2),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     Reshape(6 * 10 * 10) или Reshape(-1)\n",
    "        # )\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(196, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(self.d, 100),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(100, 196),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def generate_noise(self, num_samples):\n",
    "        \"\"\"\n",
    "        Генерирует сэмплы из априорного распределения на z.\n",
    "        Вход: num_samples, int - число сэмплов, которые надо сгененрировать.\n",
    "        Возвращаемое значение: Variable, матрица размера num_samples x d.\n",
    "        \"\"\"\n",
    "        # ваш код здесь\n",
    "        pass\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            z = z.cuda()\n",
    "        return z\n",
    "\n",
    "    def generate_samples(self, num_samples):\n",
    "        \"\"\"\n",
    "        Генерирует сэмплы из индуцируемого моделью распределения на объекты x.\n",
    "        Вход: num_samples, int - число сэмплов, которые надо сгененрировать.\n",
    "        Возвращаемое значение: Variable, матрица размера num_samples x D.\n",
    "        \"\"\"\n",
    "        # ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def discriminator_loss(self, batch):\n",
    "        \"\"\"\n",
    "        Вычисляет значение функции потерь дискриминатора на данном батче.\n",
    "        Возвращаемая оценка должна быть дифференцируема по параметрам модели (!).\n",
    "        Вход: batch, FloatTensor - матрица объектоа размера n x D.\n",
    "        Возвращаемое значение: Variable, скаляр - значение функции потерь\n",
    "        дискриминатора на данном батче.\n",
    "        \"\"\"\n",
    "        # ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def generator_loss(self, batch_size):\n",
    "        \"\"\"\n",
    "        Вычисляет значение функции потерь генератора на данном батче.\n",
    "        Возвращаемая оценка должна быть дифференцируема по параметрам модели (!).\n",
    "        Вход: batch, FloatTensor - матрица объектоа размера n x D.\n",
    "        Возвращаемое значение: Variable, скаляр - значение функции потерь\n",
    "        генератора на данном батче.\n",
    "        \"\"\"\n",
    "        # ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_mean_exp(mtx):\n",
    "    \"\"\"\n",
    "    Возвращает логарифм среднего по каждому столбцу от экспоненты данной матрицы.\n",
    "    Подсказка: не забывайте про вычислительную стабильность!\n",
    "    Вход: mtx, Varibale - матрица размера n x k.\n",
    "    Возвращаемое значение: Variable, вектор длины n.\n",
    "    \"\"\"\n",
    "    # ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood(model, num_samples=512, batch_size=4, num_batches=20):\n",
    "    \"\"\"\n",
    "    Возвращает оценку логарифма правдоподобия модели GAN методом\n",
    "    Парзеновского окна со стандартным нормальным ядром.\n",
    "    Подсказка: с аргументами по умолчанию метод должен работать несколько\n",
    "    секунд, чтобы не замедлять обучение.\n",
    "    Подсказка: sigma должна настраиваться по валидационной выборке, а\n",
    "    правдоподобие считаться по тестовой.\n",
    "    Подсказка: вместо sigma можно настраивать log_sigma.\n",
    "    Подсказка: для настойки sigma допустимо использовать как перебор по сетке,\n",
    "    так и другие методы опимизации.\n",
    "    Вход: mtx, GAN - обученная модель.\n",
    "    Вход: num_samples, int - число сэмплов z для оценки правдоподобия.\n",
    "    Вход: batch_size, int - размер батча валидационной или тестовой выборки.\n",
    "    Вход: num_batches, int - число батчей, на которых настраивается sigma или\n",
    "    считается правдоподобие.\n",
    "    Возвращаемое значение: float (не Variable!) - оценка логарифма правдоподобия.\n",
    "    \"\"\"\n",
    "    # ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, k=1, batch_size=64, num_epochs=100, learning_rate=2e-4):\n",
    "    \"\"\"\n",
    "    Обучает модель.\n",
    "    Вход: model, Module - объект, модель.\n",
    "    У этого объекта должна быть функция batch_loss от batch - FloatTensor и K - int,\n",
    "    возвращающая скаляр Variable - функцию потерь на батче, которая должна быть\n",
    "    оптимизирована.\n",
    "    Вход: k, int - число итераций оптимизации дискриминатора на итерацию оптимизации\n",
    "    генератора.\n",
    "    Вход: batch_size, int.\n",
    "    Вход: num_epochs, int.\n",
    "    Вход: learning_rate, float.\n",
    "    Возвращаемое значение: словарь с полями 'model' - обученная модель,\n",
    "    'generator_losses' - список значений функции потерь генератора,\n",
    "    'discriminator_losses' - список значений функции потерь дискриминатора.\n",
    "    \"\"\"\n",
    "    gd_generator = optim.Adam(model.generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    gd_discriminator = optim.Adam(model.discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    total_batches = len(dataloader)\n",
    "\n",
    "    generator_losses = [0]\n",
    "    discriminator_losses = [0]\n",
    "    log_likelihoods = []\n",
    "\n",
    "    if USE_CUDA:\n",
    "        model = model.cuda()\n",
    "\n",
    "    ll = log_likelihood(model)\n",
    "    log_likelihoods.append(ll)\n",
    "    print('Log-likelihood', ll, flush=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (batch, _) in enumerate(dataloader):\n",
    "            if USE_CUDA:\n",
    "                batch = batch.cuda()\n",
    "\n",
    "            # ваш код здесь!\n",
    "            # разрешается менять код этой функции для реализации\n",
    "            # более сложных процедур обучения или ускорения обучения\n",
    "            pass\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('\\rEpoch:', epoch, 'G_loss:', generator_losses[-1],\n",
    "                      'D_loss:', discriminator_losses[-1],\n",
    "                      'Batch', i + 1, 'of', total_batches,\n",
    "                      ' ' * 10, end='', flush=True)\n",
    "        print(flush=True)\n",
    "        ll = log_likelihood(model)\n",
    "        log_likelihoods.append(ll)\n",
    "        print('Log-likelihood', ll, flush=True)\n",
    "\n",
    "    return {\n",
    "        'model': model.cpu(),\n",
    "        'generator_losses': generator_losses,\n",
    "        'discriminator_losses': discriminator_losses,\n",
    "        'log_likelihoods': log_likelihoods\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time gan_model_d2 = train_model(GAN(2), k=1, num_epochs=100, learning_rate=2e-4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time gan_model_d10 = train_model(GAN(10), k=1, num_epochs=100, learning_rate=2e-4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time gan_model_d100 = train_model(GAN(100), k=1, num_epochs=100, learning_rate=2e-4, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_manifold_gan(model):\n",
    "    generator = lambda z: model.generator(Variable(torch.from_numpy(z).float())).view(14, 14).data.numpy()\n",
    "    return draw_manifold(generator)\n",
    "\n",
    "draw_manifold_gan(gan_model_d2['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_images(gan_model_d2['model'].generate_samples(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_images(gan_model_d10['model'].generate_samples(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_images(gan_model_d100['model'].generate_samples(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "for label, name, model in [\n",
    "    ('$d = 2$, D_loss', 'discriminator_losses', gan_model_d2),\n",
    "    ('$d = 2$, G_loss', 'generator_losses', gan_model_d2),\n",
    "]:\n",
    "    data = model[name]\n",
    "    x_labels = (1 + np.arange(len(data))) / len(data) * 100\n",
    "    plt.plot(x_labels, data, label=label)\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "for label, name, model in [\n",
    "    ('$d = 10$, D_loss', 'discriminator_losses', gan_model_d10),\n",
    "    ('$d = 10$, G_loss', 'generator_losses', gan_model_d10),\n",
    "]:\n",
    "    data = model[name]\n",
    "    x_labels = (1 + np.arange(len(data))) / len(data) * 100\n",
    "    plt.plot(x_labels, data, label=label)\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "for label, name, model in [\n",
    "    ('$d = 100$, D_loss', 'discriminator_losses', gan_model_d100),\n",
    "    ('$d = 100$, G_loss', 'generator_losses', gan_model_d100),\n",
    "]:\n",
    "    data = model[name]\n",
    "    x_labels = (1 + np.arange(len(data))) / len(data) * 100\n",
    "    plt.plot(x_labels, data, label=label)\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time log_likelihood(gan_model_d2['model'], num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time log_likelihood(gan_model_d10['model'], num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time log_likelihood(gan_model_d100['model'], num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "for label, name, model in [\n",
    "    ('$d = 2$, log-likelihoods', 'log_likelihoods', gan_model_d2),\n",
    "    ('$d = 10$, log-likelihoods', 'log_likelihoods', gan_model_d10),\n",
    "    ('$d = 100$, log-likelihoods', 'log_likelihoods', gan_model_d100),\n",
    "]:\n",
    "    data = model[name]\n",
    "    x_labels = (1 + np.arange(len(data)))\n",
    "    plt.plot(x_labels, data, label=label)\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
    "plt.ylabel('Log-likelihood estimation')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Выводы\n",
    "Место для ваших выводов, наблюдений, гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительное задание\n",
    "Не заглядывая в литературу, придумать свой GAN: новую процедуру обучения, адаптация для необычной задачи, использование нестандартных генатора и дискриминатора, etc.\n",
    "\n",
    "Идею описать здесь. По желанию можно также провести полное исследование и опубликовать статью."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
